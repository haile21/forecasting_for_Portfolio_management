{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cell 1\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "from task1_data_preprocessing import preprocess_data\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from pmdarima import auto_arima\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# cell 2: load data & split\n",
    "data = preprocess_data()\n",
    "pivot_close = data[\"pivot_close\"]\n",
    "series = pivot_close['TSLA'].dropna().sort_index()\n",
    "\n",
    "train_end = \"2023-12-31\"\n",
    "test_start = \"2024-01-01\"\n",
    "train = series[:train_end]\n",
    "test = series[test_start:]\n",
    "\n",
    "print(\"Train:\", train.index.min(), \"->\", train.index.max(), \" (\", len(train), \"obs )\")\n",
    "print(\"Test:\", test.index.min(), \"->\", test.index.max(), \" (\", len(test), \"obs )\")\n",
    "\n",
    "plt.figure(figsize=(12,4)); series.plot(title=\"TSLA - Closing Price\"); plt.show()\n"
   ],
   "id": "8de4d0c1cf0eaf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# cell 3: ARIMA (auto_arima), diagnose & forecast\n",
    "train_log = np.log(train)\n",
    "\n",
    "arima_model = auto_arima(train_log, seasonal=False, stepwise=True, trace=True,\n",
    "                         error_action='ignore', suppress_warnings=True,\n",
    "                         max_p=5, max_q=5, max_d=3)\n",
    "print(arima_model.summary())\n",
    "\n",
    "n_periods = len(test)\n",
    "fc_log, confint = arima_model.predict(n_periods=n_periods, return_conf_int=True)\n",
    "fc = np.exp(fc_log)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(train.index, np.exp(train_log), label='Train')\n",
    "plt.plot(test.index, test.values, label='Actual')\n",
    "plt.plot(test.index, fc, label='ARIMA Forecast')\n",
    "plt.fill_between(test.index, np.exp(confint[:,0]), np.exp(confint[:,1]), color='pink', alpha=0.3)\n",
    "plt.legend(); plt.title(\"ARIMA Forecast (log-model)\")\n",
    "plt.show()\n"
   ],
   "id": "ed9dfc30257f1a8b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# cell 4:Evaluate ARIMA\n",
    "def rmse(y_true, y_pred): return math.sqrt(mean_squared_error(y_true, y_pred))\n",
    "def mape(y_true, y_pred): return np.mean(np.abs((y_true - y_pred)/np.where(y_true==0,1e-8,y_true)))*100\n",
    "\n",
    "arima_mae = mean_absolute_error(test.values, fc)\n",
    "arima_rmse = rmse(test.values, fc)\n",
    "arima_mape = mape(test.values, fc)\n",
    "print(\"ARIMA MAE:\", arima_mae, \"RMSE:\", arima_rmse, \"MAPE:\", arima_mape)\n"
   ],
   "id": "fc2b90b49027d4de"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# cell 5: LSTM data prep\n",
    "lookback = 60\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "vals = series.values.reshape(-1,1)\n",
    "vals_scaled = scaler.fit_transform(vals)\n",
    "\n",
    "# create sequences\n",
    "def create_sequences(data, lookback):\n",
    "    X, y = [], []\n",
    "    for i in range(lookback, len(data)):\n",
    "        X.append(data[i-lookback:i, 0])\n",
    "        y.append(data[i,0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X_all, y_all = create_sequences(vals_scaled, lookback)\n",
    "dates_all = series.index[lookback:]\n",
    "\n",
    "train_mask = dates_all <= train_end\n",
    "test_mask = dates_all >= test_start\n",
    "\n",
    "X_train = X_all[train_mask]; y_train = y_all[train_mask]\n",
    "X_test = X_all[test_mask]; y_test = y_all[test_mask]\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test  = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "print(\"LSTM train shape:\", X_train.shape, \"test shape:\", X_test.shape)\n"
   ],
   "id": "3ea1f5e885fda9be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# cell 6: LSTM model training\n",
    "tf.random.set_seed(42)\n",
    "model = Sequential([\n",
    "    LSTM(64, return_sequences=True, input_shape=(X_train.shape[1], 1)),\n",
    "    Dropout(0.2),\n",
    "    LSTM(32),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, validation_split=0.1, epochs=100, batch_size=32, callbacks=[es], verbose=1)\n"
   ],
   "id": "3cb101587bb58c9d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# cell 7: LSTM forecast & evaluate\n",
    "y_pred_scaled = model.predict(X_test)\n",
    "y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "y_test_true = scaler.inverse_transform(y_test.reshape(-1,1))\n",
    "\n",
    "lstm_mae = mean_absolute_error(y_test_true, y_pred)\n",
    "lstm_rmse = rmse(y_test_true, y_pred)\n",
    "lstm_mape = mape(y_test_true.flatten(), y_pred.flatten())\n",
    "\n",
    "print(\"LSTM MAE:\", lstm_mae, \"RMSE:\", lstm_rmse, \"MAPE:\", lstm_mape)\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(test.index, test.values, label='Actual')\n",
    "# LSTM dates are dates_all[test_mask]\n",
    "lstm_dates = dates_all[test_mask]\n",
    "plt.plot(lstm_dates, y_pred.flatten(), label='LSTM Forecast')\n",
    "plt.legend(); plt.title(\"LSTM Predictions vs Actual\")\n",
    "plt.show()\n"
   ],
   "id": "6c39d48831f571f6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# cell 8: Compare & conclude\n",
    "print(\"ARIMA -> MAE, RMSE, MAPE:\", arima_mae, arima_rmse, arima_mape)\n",
    "print(\"LSTM  -> MAE, RMSE, MAPE:\", lstm_mae, lstm_rmse, lstm_mape)\n",
    "\n",
    "# Save metrics to CSV/JSON if desired\n",
    "metrics = {\n",
    "    \"arima\": {\"mae\":float(arima_mae),\"rmse\":float(arima_rmse),\"mape\":float(arima_mape)},\n",
    "    \"lstm\":  {\"mae\":float(lstm_mae),\"rmse\":float(lstm_rmse),\"mape\":float(lstm_mape)}\n",
    "}\n",
    "import json\n",
    "with open(\"task2_metrics.json\",\"w\") as f:\n",
    "    json.dump(metrics,f,indent=2)\n",
    "\n",
    "# Brief discussion placeholder\n",
    "print(\"\\nDiscussion:\\n- Compare metrics and visual shape of forecasts.\\n- ARIMA may be strong for linear, stationary dynamics after differencing.\\n- LSTM may capture nonlinear patterns but needs more data/tuning and careful validation.\\n\")\n"
   ],
   "id": "cca62ff9ddfece03"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
